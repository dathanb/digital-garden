---
created: 2022-10-16T11:06:22-07:00
updated: 2022-10-16T11:13:48-07:00
---

# Links
- [Wikipedia article on Word embedding](https://en.wikipedia.org/wiki/Word_embedding)

# Types of embeddings
[Adrien Sieg lists 9 embeddings](https://medium.com/@adriensieg/text-similarities-da019229c894)
- Bag of Words (BoW) (also known as Count Vectorizer)
- Term Frequency - Inverse Document Frequency (TF-IDF)
- Continuous BoW (CBOW) model and SkipGram model embedding(SkipGram)
- Pre-trained word embedding models : 
     -  Word2Vec (by Google)
     -  GloVe (by Stanford)
     -  fastText (by Facebook)
- Poincarr√© embedding
- Node2Vec embedding based on Random Walk and Graph
